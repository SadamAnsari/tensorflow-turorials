{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import seaborn as sns\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert String category variables to Integer category variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.Species = iris.Species.replace(to_replace=['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], value=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0   1            5.1           3.5            1.4           0.2        0\n",
       "1   2            4.9           3.0            1.4           0.2        0\n",
       "2   3            4.7           3.2            1.3           0.2        0\n",
       "3   4            4.6           3.1            1.5           0.2        0\n",
       "4   5            5.0           3.6            1.4           0.2        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit this data in a one layer logistic regression model, the data needs to be linearly separable. Let's see if that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b141a6fa90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(iris[:50].SepalLengthCm, iris[:50].SepalWidthCm, label='Iris-setosa')\n",
    "plt.scatter(iris[51:100].SepalLengthCm, iris[51:100].SepalWidthCm, label='Iris-versicolo')\n",
    "plt.scatter(iris[101:].SepalLengthCm, iris[101:].SepalWidthCm, label='Iris-versicolo')\n",
    "plt.xlabel('SepalLength')\n",
    "plt.ylabel('SepalWidth')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just keep the columns with features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop(labels=['Id', 'Species'], axis=1).values\n",
    "y = iris.Species.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1]]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly select indexes to use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = np.random.choice(len(X), round(len(X) * 0.6), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 72, 112, 132,  88,  37, 138,  87,  42,   8,  90, 141,  33,  59,\n",
       "       116, 135, 104,  36,  13,  63,  45,  28, 133,  24, 127,  46,  20,\n",
       "        31, 121, 117,   4, 130, 119,  29,   0,  62,  93, 131,   5,  16,\n",
       "        82,  60,  35, 143, 145, 142, 114, 136,  53,  19,  38, 110,  23,\n",
       "         9,  86,  91,  89,  79, 101,  65, 115,  41, 124,  95,  21,  11,\n",
       "       103,  74, 122, 118,  44,  51,  81, 149,  12, 129,  56,  50,  25,\n",
       "       128, 146,  43,   1,  71,  54, 100,  14,   6,  80,  26,  70])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = np.array(list(set(range(len(X))) - set(train_index)))\n",
    "train_X = X[train_index]\n",
    "train_y = y[train_index]\n",
    "test_X = X[test_index]\n",
    "test_y = y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2,   3, 134,   7, 137,  10, 139, 140,  15, 144,  17,  18, 147,\n",
       "        148,  22,  27,  30,  32,  34,  39,  40,  47,  48,  49,  52,  55,\n",
       "         57,  58,  61,  64,  66,  67,  68,  69,  73,  75,  76,  77,  78,\n",
       "         83,  84,  85,  92,  94,  96,  97,  98,  99, 102, 105, 106, 107,\n",
       "        108, 109, 111, 113, 120, 123, 125, 126]), 60)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index, len(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.3, 2.5, 4.9, 1.5],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [5.5, 2.6, 4.4, 1.2]]),\n",
       " array([1, 2, 2, 1, 0, 2, 1, 0, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0:10], train_y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalized(data):\n",
    "    col_max = np.max(data, axis=0)\n",
    "    col_min = np.min(data, axis=0)\n",
    "    return np.divide(data - col_min, col_max - col_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = min_max_normalized(train_X)\n",
    "test_X = min_max_normalized(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55555556, 0.22727273, 0.65517241, 0.58333333],\n",
       "       [0.69444444, 0.45454545, 0.75862069, 0.83333333],\n",
       "       [0.58333333, 0.36363636, 0.77586207, 0.875     ],\n",
       "       [0.36111111, 0.45454545, 0.51724138, 0.5       ],\n",
       "       [0.16666667, 0.5       , 0.06896552, 0.        ],\n",
       "       [0.47222222, 0.45454545, 0.63793103, 0.70833333],\n",
       "       [0.55555556, 0.13636364, 0.56896552, 0.5       ],\n",
       "       [0.02777778, 0.54545455, 0.03448276, 0.04166667],\n",
       "       [0.02777778, 0.40909091, 0.05172414, 0.04166667],\n",
       "       [0.33333333, 0.27272727, 0.56896552, 0.45833333]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Tensorflow Graph\n",
    "Let's start building Tensorflow model. Tensorflow is a graph based framework. So we have to build the whole graph of our model before we start any kind of training. For most ML problems, the graph building process is pretty straight forward.\n",
    "\n",
    "- Step 1: Define placeholders for input Data and Labels.\n",
    "- Step 2: Pass the Data through the layers.\n",
    "- Step 3: Define a loss function.\n",
    "- Step 4: Apply Gradient Descent (or other optimisers) on the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders are special type of Tensorflow variables. These variables don't hold any particular values and are used as input nodes to the graph. The data is fed to these variables in order to Train the model or infer using the model.\n",
    "\n",
    "- \"data\" is used for data input. The shape is Batch Size x Input Features. \n",
    "- \"labels\" is used for output labels. Batch Size x Output Space\n",
    "\n",
    "To keep the batch size \"variable\", we use None instead of a specific Batch Size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.placeholder(dtype=tf.float32, shape=[None, 4], name='Data_Input')\n",
    "labels = tf.placeholder(dtype=tf.int32, shape=[None, 1], name='Labels_Input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Data_Input:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(4)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pass the data through all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_size = 3\n",
    "logits = tf.layers.dense(inputs=data, units=labels_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the logits calculated, lets add the loss operation. Since we're doing logistic regression, the loss function is sigmoid cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'loss:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels = tf.one_hot(tf.cast(labels, tf.int32), depth=labels_size)\n",
    "one_hot_labels = tf.squeeze(one_hot_labels)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=one_hot_labels))\n",
    "tf.summary.scalar('loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "batch_size = 30\n",
    "iter_num = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our model, we iterate on the parameter values such that the loss is minimized. To reduce the loss, we have multiple Optimizers available. Let's use Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction and Accuracy utility operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the accuracy\n",
    "# The default threshold is 0.5, rounded off directly\n",
    "prediction = tf.cast(tf.argmax(input=logits, axis=1, name='Prediction'), dtype=tf.int32)\n",
    "# Bool into float32 type\n",
    "correct = tf.cast(tf.equal(tf.squeeze(prediction), tf.squeeze(labels)), dtype=tf.float32)\n",
    "# Average\n",
    "accuracy = tf.reduce_mean(correct, name='Accuracy')\n",
    "\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "# End of the definition of the model framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_trace = []\n",
    "train_acc = []\n",
    "test_acc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training / Evaluating the model\n",
    "Up until now, we have just built the graph of model in Tensorflow. Now we will start trainig and evaluating the model. To use the model:\n",
    "- Initialise the model.\n",
    "- To \"Train\" the model: feed data and labels and process the model till the \"goal\" operation.\n",
    "- To \"Evaluate\" the model: provide data and lables and process till \"accuracy\" operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation is pretty standard. We get a session object after initialisation and this session object is used to interact with the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter('./logistic_regression', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model:\n",
    "- Get a batch of data and labels.\n",
    "- Feed data and labels to the graph.\n",
    "- Check the Train and Test data accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  300 loss: 1.054962 train_acc: 0.355556 test_acc: 0.316667\n",
      "epoch:  600 loss: 1.034553 train_acc: 0.411111 test_acc: 0.383333\n",
      "epoch:  900 loss: 0.934401 train_acc: 0.700000 test_acc: 0.583333\n",
      "epoch: 1200 loss: 0.838584 train_acc: 0.733333 test_acc: 0.633333\n",
      "epoch: 1500 loss: 0.924443 train_acc: 0.755556 test_acc: 0.666667\n",
      "epoch: 1800 loss: 0.836608 train_acc: 0.766667 test_acc: 0.666667\n",
      "epoch: 2100 loss: 0.849139 train_acc: 0.777778 test_acc: 0.666667\n",
      "epoch: 2400 loss: 0.757630 train_acc: 0.777778 test_acc: 0.666667\n",
      "epoch: 2700 loss: 0.768777 train_acc: 0.800000 test_acc: 0.666667\n",
      "epoch: 3000 loss: 0.670883 train_acc: 0.800000 test_acc: 0.700000\n",
      "epoch: 3300 loss: 0.669076 train_acc: 0.800000 test_acc: 0.700000\n",
      "epoch: 3600 loss: 0.674075 train_acc: 0.800000 test_acc: 0.700000\n",
      "epoch: 3900 loss: 0.613756 train_acc: 0.800000 test_acc: 0.700000\n",
      "epoch: 4200 loss: 0.679639 train_acc: 0.800000 test_acc: 0.700000\n",
      "epoch: 4500 loss: 0.667105 train_acc: 0.800000 test_acc: 0.700000\n",
      "epoch: 4800 loss: 0.686495 train_acc: 0.800000 test_acc: 0.700000\n",
      "epoch: 5100 loss: 0.590016 train_acc: 0.811111 test_acc: 0.700000\n",
      "epoch: 5400 loss: 0.538710 train_acc: 0.811111 test_acc: 0.700000\n",
      "epoch: 5700 loss: 0.608830 train_acc: 0.811111 test_acc: 0.700000\n",
      "epoch: 6000 loss: 0.607000 train_acc: 0.811111 test_acc: 0.716667\n",
      "epoch: 6300 loss: 0.562140 train_acc: 0.822222 test_acc: 0.716667\n",
      "epoch: 6600 loss: 0.560445 train_acc: 0.822222 test_acc: 0.733333\n",
      "epoch: 6900 loss: 0.452128 train_acc: 0.822222 test_acc: 0.733333\n",
      "epoch: 7200 loss: 0.595208 train_acc: 0.822222 test_acc: 0.733333\n",
      "epoch: 7500 loss: 0.459839 train_acc: 0.822222 test_acc: 0.750000\n",
      "epoch: 7800 loss: 0.553798 train_acc: 0.822222 test_acc: 0.750000\n",
      "epoch: 8100 loss: 0.654959 train_acc: 0.822222 test_acc: 0.766667\n",
      "epoch: 8400 loss: 0.613828 train_acc: 0.822222 test_acc: 0.750000\n",
      "epoch: 8700 loss: 0.478705 train_acc: 0.822222 test_acc: 0.766667\n",
      "epoch: 9000 loss: 0.526882 train_acc: 0.833333 test_acc: 0.766667\n",
      "epoch: 9300 loss: 0.563453 train_acc: 0.844444 test_acc: 0.800000\n",
      "epoch: 9600 loss: 0.433723 train_acc: 0.822222 test_acc: 0.766667\n",
      "epoch: 9900 loss: 0.562731 train_acc: 0.844444 test_acc: 0.800000\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "for epoch in range(iter_num):\n",
    "    # Generate random batch index\n",
    "    batch_index = np.random.choice(len(train_X), size=batch_size)\n",
    "    batch_train_X = train_X[batch_index]\n",
    "    batch_train_y = np.matrix(train_y[batch_index]).T\n",
    "    \n",
    "    _, summary = sess.run([goal, merged], feed_dict={data: batch_train_X, labels: batch_train_y})\n",
    "    temp_loss = sess.run(loss, feed_dict={data: batch_train_X, labels: batch_train_y})\n",
    "    \n",
    "    train_logit, train_pred, train_corr, train_label = sess.run([logits, prediction, correct, labels],\n",
    "                                                   feed_dict={data: test_X, labels: np.matrix(test_y).T})\n",
    "        \n",
    "    # convert into a matrix, and the shape of the placeholder to correspond\n",
    "    temp_train_acc = sess.run(accuracy, feed_dict={data: train_X, labels: np.matrix(train_y).T})\n",
    "    temp_test_acc = sess.run(accuracy, feed_dict={data: test_X, labels: np.matrix(test_y).T})\n",
    "    # recode the result\n",
    "    loss_trace.append(temp_loss)\n",
    "    train_acc.append(temp_train_acc)\n",
    "    test_acc.append(temp_test_acc)\n",
    "    train_writer.add_summary(summary, epoch)\n",
    "    # output\n",
    "    if (epoch + 1) % 300 == 0:\n",
    "        print('epoch: {:4d} loss: {:5f} train_acc: {:5f} test_acc: {:5f}'.format(epoch + 1, temp_loss,\n",
    "                                                                          temp_train_acc, temp_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the results\n",
    "# loss function\n",
    "plt.plot(loss_trace)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc, 'b-', label='train accuracy')\n",
    "plt.plot(test_acc, 'k-', label='test accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Train and Test Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
